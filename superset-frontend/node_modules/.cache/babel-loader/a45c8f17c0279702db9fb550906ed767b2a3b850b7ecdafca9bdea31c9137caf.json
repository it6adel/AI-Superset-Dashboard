{"ast":null,"code":"/**\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\nimport { Children, cloneElement } from 'react';\nimport { nanoid } from 'nanoid';\nimport { SupersetClient, tn } from '@superset-ui/core';\nimport rison from 'rison';\n\nexport function recurseReactClone(children, type, propExtender) {\n  /**\n   * Clones a React component's children, and injects new props\n   * where the type specified is matched.\n   */\n  return Children.map(children, (child) => {\n    let newChild = child;\n    if (child && child.type.name === type.name) {\n      newChild = /*#__PURE__*/cloneElement(child, propExtender(child));\n    }\n    if (newChild && newChild.props.children) {\n      newChild = /*#__PURE__*/cloneElement(newChild, {\n        children: recurseReactClone(\n          newChild.props.children,\n          type,\n          propExtender\n        )\n      });\n    }\n    return newChild;\n  });\n}\n\nexport function updateColumns(prevCols, newCols, addSuccessToast) {\n  // cols: Array<{column_name: string; is_dttm: boolean; type: string;}>\n  const databaseColumnNames = newCols.map((col) => col.column_name);\n  const currentCols = prevCols.reduce((agg, col) => {\n    // eslint-disable-next-line no-param-reassign\n    agg[col.column_name] = col;\n    return agg;\n  }, {});\n  const columnChanges = {\n    added: [],\n    modified: [],\n    removed: prevCols.\n    filter(\n      (col) =>\n      !(col.expression || databaseColumnNames.includes(col.column_name))\n    ).\n    map((col) => col.column_name),\n    finalColumns: []\n  };\n  newCols.forEach((col) => {\n    const currentCol = currentCols[col.column_name];\n    if (!currentCol) {\n      // new column\n      columnChanges.finalColumns.push({\n        id: nanoid(),\n        column_name: col.column_name,\n        type: col.type,\n        groupby: true,\n        filterable: true,\n        is_dttm: col.is_dttm\n      });\n      columnChanges.added.push(col.column_name);\n    } else if (\n    currentCol.type !== col.type ||\n    currentCol.is_dttm !== col.is_dttm)\n    {\n      // modified column\n      columnChanges.finalColumns.push({\n        ...currentCol,\n        type: col.type,\n        is_dttm: currentCol.is_dttm || col.is_dttm\n      });\n      columnChanges.modified.push(col.column_name);\n    } else {\n      // unchanged\n      columnChanges.finalColumns.push(currentCol);\n    }\n  });\n  // push all calculated columns\n  prevCols.\n  filter((col) => col.expression).\n  forEach((col) => {\n    columnChanges.finalColumns.push(col);\n  });\n\n  if (columnChanges.modified.length) {\n    addSuccessToast(\n      tn(\n        'Modified 1 column in the virtual dataset',\n        'Modified %s columns in the virtual dataset',\n        columnChanges.modified.length\n      )\n    );\n  }\n  if (columnChanges.removed.length) {\n    addSuccessToast(\n      tn(\n        'Removed 1 column from the virtual dataset',\n        'Removed %s columns from the virtual dataset',\n        columnChanges.removed.length\n      )\n    );\n  }\n  if (columnChanges.added.length) {\n    addSuccessToast(\n      tn(\n        'Added 1 new column to the virtual dataset',\n        'Added %s new columns to the virtual dataset',\n        columnChanges.added.length\n      )\n    );\n  }\n  return columnChanges;\n}\n\nexport async function fetchSyncedColumns(datasource) {var _datasource$database, _datasource$database2;\n  const params = {\n    datasource_type: datasource.type || datasource.datasource_type,\n    database_name:\n    ((_datasource$database = datasource.database) == null ? void 0 : _datasource$database.database_name) || ((_datasource$database2 = datasource.database) == null ? void 0 : _datasource$database2.name),\n    catalog_name: datasource.catalog,\n    schema_name: datasource.schema,\n    table_name: datasource.table_name,\n    normalize_columns: datasource.normalize_columns,\n    always_filter_main_dttm: datasource.always_filter_main_dttm\n  };\n  Object.entries(params).forEach(([key, value]) => {\n    // rison can't encode the undefined value\n    if (value === undefined) {\n      params[key] = null;\n    }\n  });\n  const endpoint = `/datasource/external_metadata_by_name/?q=${rison.encode_uri(\n    params\n  )}`;\n  const { json } = await SupersetClient.get({ endpoint });\n  return json;\n}","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}